import streamlit as st
from langgraph.graph import StateGraph, END
from typing import TypedDict, Optional
import os
import requests
import re

os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"] if "GROQ_API_KEY" in st.secrets else os.getenv("GROQ_API_KEY")

class State(TypedDict):
    user_input: str
    parsed_info: Optional[dict]
    report: Optional[str]

def call_groq_llm(prompt_messages):
    headers = {
        "Authorization": f"Bearer {os.getenv('GROQ_API_KEY')}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "deepseek-r1-distill-llama-70b",
        "messages": prompt_messages,
        "temperature": 0.7
    }
    response = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers=headers,
        json=payload
    )
    if response.ok:
        return response.json()["choices"][0]["message"]["content"]
    else:
        return f"[Groq API é”™è¯¯] {response.status_code}: {response.text}"

def recognition_user_input(state: State) -> dict:
    user_input = state['user_input']
    prompt = [
        {"role": "system", "content": (
            "ä½ æ˜¯ä¸€ä¸ªå‡ºæµ·é¡¾é—®åŠ©æ‰‹ï¼Œéœ€è¦ç”¨æˆ·æä¾›å®Œæ•´çš„ä¼ä¸šå‡ºæµ·èƒŒæ™¯åæ‰èƒ½è¿›è¡Œåˆ†æã€‚\n"
            "è¯·æå–ä»¥ä¸‹å­—æ®µï¼š\n"
            "- å‡ºæµ·å›½å®¶æˆ–åœ°åŒºï¼ˆå¿…å¡«ï¼‰\n"
            "- ä¼ä¸šä¸»è¥ä¸šåŠ¡æˆ–è¡Œä¸šï¼ˆå¿…å¡«ï¼‰\n"
            "è¯·ä»¥ JSON æ ¼å¼è¿”å›å­—æ®µå€¼ã€‚"
        )},
        {"role": "user", "content": user_input}
    ]
    content = call_groq_llm(prompt)
    try:
        parsed = eval(content)
        if isinstance(parsed, dict) and 'å›½å®¶' in parsed and 'è¡Œä¸š' in parsed:
            return {"parsed_info": parsed}
        else:
            return {"parsed_info": {"å›½å®¶": "æœªçŸ¥", "è¡Œä¸š": "æœªçŸ¥", "å¤‡æ³¨": content}, "debug": content}
    except:
        return {"parsed_info": {"å›½å®¶": "æœªçŸ¥", "è¡Œä¸š": "æœªçŸ¥", "å¤‡æ³¨": content}, "debug": content}

def report_generator(state: State) -> dict:
    parsed = state["parsed_info"]
    prompt = [
        {"role": "system", "content": (
            f"è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯æ’°å†™ä¸€ä»½å‡ºæµ·å»ºè®®æŠ¥å‘Šï¼Œç»“æ„åŒ…å«ï¼š\n"
            f"1. ä¼ä¸šèƒŒæ™¯ï¼š{parsed}\n"
            "2. å¸‚åœºåˆ†æï¼šè¯·æ ¹æ®è¯¥ä¼ä¸šèƒŒæ™¯æ¨æµ‹å…¶åœ¨ç›®æ ‡å¸‚åœºå¯èƒ½é¢ä¸´çš„æœºä¼šä¸æŒ‘æˆ˜ã€‚\n"
            "è¦æ±‚å†…å®¹è¿è´¯ï¼Œç»“æ„æ¸…æ™°ï¼Œè¯­è¨€ä¸“ä¸šï¼Œä¸å°‘äº150å­—ï¼Œä½¿ç”¨ä¸­æ–‡æ’°å†™ã€‚å¹¶åœ¨å›ç­”ä¸­ä½¿ç”¨ <think>ä½ çš„æ€è€ƒè¿‡ç¨‹</think> æ ‡ç­¾åŒ…è£…æ¨ç†å†…å®¹ã€‚"
        )}
    ]
    full_output = call_groq_llm(prompt)
    # æŠ½å–æ¨ç†è¿‡ç¨‹
    match = re.search(r"<think>(.*?)</think>", full_output, re.DOTALL)
    debug_info = match.group(1).strip() if match else "ï¼ˆæ— æ¨ç†è¿‡ç¨‹æ ‡æ³¨ï¼‰"
    cleaned_output = re.sub(r"<think>.*?</think>", "", full_output, flags=re.DOTALL).strip()
    return {"report": cleaned_output, "debug": debug_info}

graph = StateGraph(State)
graph.add_node("parse", recognition_user_input)
graph.add_node("report_gen", report_generator)

graph.set_entry_point("parse")
graph.add_edge("parse", "report_gen")
graph.add_edge("report_gen", END)

app = graph.compile()

def main():
    st.set_page_config(page_title="å‡ºæµ·é¡¾é—®åŠ©æ‰‹", page_icon="ğŸŒ")
    st.title("ğŸŒ ä¼ä¸šå‡ºæµ·æ™ºèƒ½å¯¹è¯åŠ©æ‰‹")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "full_trace" not in st.session_state:
        st.session_state.full_trace = []

    with st.sidebar:
        if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯"):
            st.session_state.clear()
            st.rerun()

    for i, (role, msg, trace) in enumerate(st.session_state.full_trace):
        with st.chat_message(role):
            st.markdown(msg)
            if role == "assistant" and trace:
                with st.expander("æ¨ç†è¿‡ç¨‹å±•å¼€", expanded=False):
                    st.code(trace)

    user_prompt = st.chat_input("è¯·è¾“å…¥æ‚¨çš„ä¼ä¸šå‡ºæµ·èƒŒæ™¯æˆ–æé—®â€¦")
    if user_prompt:
        st.chat_message("user").markdown(user_prompt)
        st.session_state.full_trace.append(("user", user_prompt, None))

        with st.spinner("æ­£åœ¨ç”Ÿæˆå‡ºæµ·å»ºè®®â€¦"):
            result = app.invoke({"user_input": user_prompt})
            report = result["report"]
            debug = result.get("debug", "æ— æ¨ç†å†…å®¹")

        st.chat_message("assistant").markdown(report)
        st.session_state.full_trace.append(("assistant", report, debug))

if __name__ == "__main__":
    main()
