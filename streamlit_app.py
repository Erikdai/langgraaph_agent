import streamlit as st
from langgraph.graph import StateGraph, END
from typing import TypedDict, Optional
import os
import requests

os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"] if "GROQ_API_KEY" in st.secrets else os.getenv("GROQ_API_KEY")

class State(TypedDict):
    user_input: str
    parsed_info: Optional[dict]
    report: Optional[str]

def call_groq_llm(prompt_messages):
    headers = {
        "Authorization": f"Bearer {os.getenv('GROQ_API_KEY')}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "deepseek-r1-distill-llama-70b",
        "messages": prompt_messages,
        "temperature": 0.7
    }
    response = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers=headers,
        json=payload
    )
    if response.ok:
        return response.json()["choices"][0]["message"]["content"]
    else:
        return f"[Groq API é”™è¯¯] {response.status_code}: {response.text}"

def recognition_user_input(state: State) -> dict:
    user_input = state['user_input']
    prompt = [
        {"role": "system", "content": (
            "ä½ æ˜¯ä¸€ä¸ªå‡ºæµ·é¡¾é—®åŠ©æ‰‹ï¼Œéœ€è¦ç”¨æˆ·æä¾›å®Œæ•´çš„ä¼ä¸šå‡ºæµ·èƒŒæ™¯åæ‰èƒ½è¿›è¡Œåˆ†æã€‚\n"
            "è¯·æå–ä»¥ä¸‹å­—æ®µï¼š\n"
            "- å‡ºæµ·å›½å®¶æˆ–åœ°åŒºï¼ˆå¿…å¡«ï¼‰\n"
            "- ä¼ä¸šä¸»è¥ä¸šåŠ¡æˆ–è¡Œä¸šï¼ˆå¿…å¡«ï¼‰\n"
            "è¯·ä»¥ JSON æ ¼å¼è¿”å›å­—æ®µå€¼ã€‚"
        )},
        {"role": "user", "content": user_input}
    ]
    content = call_groq_llm(prompt)
    try:
        parsed = eval(content)
        if isinstance(parsed, dict) and 'å›½å®¶' in parsed and 'è¡Œä¸š' in parsed:
            return {"parsed_info": parsed}
        else:
            return {"parsed_info": {"å›½å®¶": "æœªçŸ¥", "è¡Œä¸š": "æœªçŸ¥", "å¤‡æ³¨": content}}
    except:
        return {"parsed_info": {"å›½å®¶": "æœªçŸ¥", "è¡Œä¸š": "æœªçŸ¥", "å¤‡æ³¨": content}}

def report_generator(state: State) -> dict:
    parsed = state["parsed_info"]
    prompt = [
        {"role": "system", "content": (
            f"è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯æ’°å†™ä¸€ä»½å‡ºæµ·å»ºè®®æŠ¥å‘Šï¼Œç»“æ„åŒ…å«ï¼š\n"
            f"1. ä¼ä¸šèƒŒæ™¯ï¼š{parsed}\n"
            "2. å¸‚åœºåˆ†æï¼šè¯·æ ¹æ®è¯¥ä¼ä¸šèƒŒæ™¯æ¨æµ‹å…¶åœ¨ç›®æ ‡å¸‚åœºå¯èƒ½é¢ä¸´çš„æœºä¼šä¸æŒ‘æˆ˜ã€‚\n"
            "è¦æ±‚å†…å®¹è¿è´¯ï¼Œç»“æ„æ¸…æ™°ï¼Œè¯­è¨€ä¸“ä¸šï¼Œä¸å°‘äº150å­—ï¼Œä½¿ç”¨ä¸­æ–‡æ’°å†™ã€‚"
        )}
    ]
    return {"report": call_groq_llm(prompt)}

graph = StateGraph(State)
graph.add_node("parse", recognition_user_input)
graph.add_node("report_gen", report_generator)

graph.set_entry_point("parse")
graph.add_edge("parse", "report_gen")
graph.add_edge("report_gen", END)

app = graph.compile()

def main():
    st.set_page_config(page_title="å‡ºæµ·é¡¾é—®åŠ©æ‰‹", page_icon="ğŸŒ")
    st.title("ğŸŒ ä¼ä¸šå‡ºæµ·æ™ºèƒ½å¯¹è¯åŠ©æ‰‹")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    for role, msg in st.session_state.chat_history:
        if role == "user":
            st.chat_message("user").markdown(msg)
        else:
            st.chat_message("assistant").markdown(msg)

    user_prompt = st.chat_input("è¯·è¾“å…¥æ‚¨çš„ä¼ä¸šå‡ºæµ·èƒŒæ™¯æˆ–æé—®â€¦")
    if user_prompt:
        st.chat_message("user").markdown(user_prompt)
        st.session_state.chat_history.append(("user", user_prompt))

        with st.spinner("æ­£åœ¨ç”Ÿæˆå‡ºæµ·å»ºè®®â€¦"):
            result = app.invoke({"user_input": user_prompt})
            report = result["report"]

        st.chat_message("assistant").markdown(report)
        st.session_state.chat_history.append(("assistant", report))

if __name__ == "__main__":
    main()
